{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scraping\n",
    "Scrape the front page of some always-updating website, such as\n",
    "\n",
    "https://www.slickdeals.net/ (Links to an external site.)Links to an external site.\n",
    "https://www.reddit.com (Links to an external site.)Links to an external site./\n",
    "https://www.washingtonpost.com (Links to an external site.)Links to an external site./\n",
    "https://finance.yahoo.com/industries (Links to an external site.)Links to an external site.\n",
    "anything else, really\n",
    "Note that some of these won't work with BeautifulSoup!\n",
    "\n",
    "Send yourself an email with as much information as possible from the site, such as:\n",
    "\n",
    "The title of the thing (the sale, the article, whatever)\n",
    "A URL for it\n",
    "Upvotes/thumbs ups/subreddits/prices/links to images/etc\n",
    "Save this as a CSV, and send it as an attachment to your email address every 6 hours. The email headline should say something like \"Here is your 6PM briefing.\" The CSV file should be timestamped with the current date and time, e.g. briefing-2018-06-18-3PM.csv\n",
    "\n",
    "BONUS: Have the content actually be the body of the email, not just an attachment. I don't mean like a CSV or whatever, I mean it should actually look like nice lists and stuff, a real email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I picked the NY Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://www.nytimes.com')\n",
    "doc = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing url\n",
    "\n",
    "# stories = doc.find_all(class_ ='story')\n",
    "# print(stories[0].h1.a['href'])\n",
    "# stories[1].h2.a['href']\n",
    "# stories[0].a['href']\n",
    "# stories[2].a['href']\n",
    "# stories[3].a['href']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"id\": \"<20180620203522.1.6C369B9A164D3A21@sandbox640aad25f01942ddad29a078ff170d9b.mailgun.org>\",\\n  \"message\": \"Queued. Thank you.\"\\n}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories = doc.find_all(class_ ='story')\n",
    "list_of_stories = []\n",
    "\n",
    "for story in stories:\n",
    "    story_dict = {}\n",
    "    headline = story.find(class_='story-heading')\n",
    "    byline = story.find(class_='byline')\n",
    "    time =story.find(class_=\"timestamp\")\n",
    "    summary = story.find(class_=\"summary\")\n",
    "   \n",
    "    \n",
    "    if headline:\n",
    "        story_dict['headline'] = headline.text.strip()\n",
    "    if byline:\n",
    "        story_dict['byline'] = byline.text.strip()\n",
    "    if time:\n",
    "        story_dict['time']= time.text.strip()\n",
    "    if summary:\n",
    "        story_dict['summary']=summary.text.strip()\n",
    "    # there's a story without the url\n",
    "    try:\n",
    "        story_dict['url']= story.a['href']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    list_of_stories.append(story_dict)\n",
    "    \n",
    "###Test my list:\n",
    "# list_of_stories\n",
    "\n",
    "df = pd.DataFrame(list_of_stories)\n",
    "right_now = datetime.datetime.now()\n",
    "# This will set sth like NYT-briefing-2018-06-18-3PM.csv\n",
    "file_date_string = right_now.strftime(\"%Y-%m-%d-%-I%p\")\n",
    "df.to_csv('NYT-briefing-{}.csv'.format(file_date_string), index=False)\n",
    "\n",
    "# This set the email subject time: Here is your 6PM briefing\n",
    "mail_date_string =right_now.strftime(\"%-I%p\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = requests.post(\n",
    "        \"https://api.mailgun.net/v3/MY_DOMIAN/messages\", \n",
    "        auth=(\"api\", \"MY_API_KEY\"),\n",
    "        files=[(\"attachment\", open('NYT-briefing-{}.csv'.format(file_date_string)))],\n",
    "        data={\"from\": \"DIAN ZHANG <dz2383@columbia.edu>\",\n",
    "              \"to\": [\"dz2383@columbia.edu\"],\n",
    "              \"subject\": 'Here is your {} briefing'.format(mail_date_string),\n",
    "              \"text\": \"Please check the attachment\"}) \n",
    "              \n",
    "response.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
